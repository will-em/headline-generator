{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What do you expect? They're savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I've never seen wildlings do a thing like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence  \n",
       "0  What do you expect? They're savages. One lot s...  \n",
       "1  I've never seen wildlings do a thing like this...  \n",
       "2                             How close did you get?  \n",
       "3                            Close as any man would.  \n",
       "4                   We should head back to the wall.  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Game_of_Thrones_Script.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you expect? they're savages. one lot steals a goat from another lot and before you know it, they're ripping each other to pieces.\n",
      "i've never seen wildlings do a thing like this. i've never seen a thing like this, not ever in my life.\n",
      "how close did you get?\n",
      "close as any man would.\n",
      "we should head back to the wall.\n",
      "do the dead frighten you?\n",
      "our orders were to track the wildlings. we tracked them. they won't trouble us no more.\n",
      "you don't think he'll ask us how they died? get back on your hor\n"
     ]
    }
   ],
   "source": [
    "lines = df[\"Sentence\"].to_list()\n",
    "\n",
    "corpus = \"\"\n",
    "for line in lines:\n",
    "    corpus += (line.lower() + \"\\n\")\n",
    "\n",
    "print(corpus[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 9889\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus = re.split(\"([^a-zA-Z0-9\\w'])\",corpus)\n",
    "corpus = [x for x in corpus if x != ' ' and x != '']\n",
    "word_counts = Counter(corpus)\n",
    "sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "int_to_vocab = {k:w for k, w in enumerate(sorted_vocab)}\n",
    "vocab_to_int = {w:k for k, w in int_to_vocab.items()}\n",
    "n_vocab = len(int_to_vocab)\n",
    "print(f\"Number of unique words: {n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_size=8\n",
    "batch_size=64\n",
    "int_text = [vocab_to_int[w] for w in corpus]\n",
    "num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "out_text = np.zeros_like(in_text)\n",
    "out_text[:-1] = in_text[1:]\n",
    "out_text[-1] = in_text[0]\n",
    "in_text = np.reshape(in_text, (batch_size, -1))\n",
    "out_text = np.reshape(out_text, (batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, hidden_dim):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.num_of_layers = 1\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            hidden_dim,\n",
    "                            num_layers = self.num_of_layers,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_dim, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(self.num_of_layers, batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_of_layers, batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5, num_of_words = 100):\n",
    "    net.eval()\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    for _ in range(num_of_words):\n",
    "        ix = torch.tensor([[choice]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_norm = 5\n",
    "embedding_size=64\n",
    "hidden_dim=256\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    net = RNNModule(n_vocab, seq_size,\n",
    "                    embedding_size, hidden_dim)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "    iteration = 0\n",
    "    for e in range(200):\n",
    "        batches = get_batches(in_text, out_text, batch_size, seq_size)\n",
    "        state_h, state_c = net.zero_state(batch_size)\n",
    "        \n",
    "        # Transfer data to GPU\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "            \n",
    "            # Tell it we are in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Transfer data to GPU\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.tensor(y).to(device)\n",
    "\n",
    "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y.long())\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # Perform back-propagation\n",
    "            loss.backward()\n",
    "        \n",
    "            _ = torch.nn.utils.clip_grad_norm_(\n",
    "                net.parameters(), gradients_norm)\n",
    "\n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(e, 200),\n",
    "                      'Iteration: {}'.format(iteration),\n",
    "                      'Loss: {}'.format(loss_value))\n",
    "\n",
    "            if iteration % 1000 == 0:\n",
    "                test_initial_words = [\"i\", \"am\"]\n",
    "                predict(device, net, test_initial_words, n_vocab,\n",
    "                        vocab_to_int, int_to_vocab, top_k=5)\n",
    "                torch.save(net.state_dict(),\n",
    "                           'models/model-{}.pth'.format(iteration))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000017?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb Cell 17'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=40'>41</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=42'>43</a>\u001b[0m \u001b[39m# Perform back-propagation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=43'>44</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=45'>46</a>\u001b[0m _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=46'>47</a>\u001b[0m     net\u001b[39m.\u001b[39mparameters(), gradients_norm)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamemanuelsson/Documents/GitHub/headline-generator/main.ipynb#ch0000016?line=48'>49</a>\u001b[0m \u001b[39m# Update the network's parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RNN/lib/python3.10/site-packages/torch/_tensor.py:401\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    393\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    394\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    395\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    400\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 401\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/RNN/lib/python3.10/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    193\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9384, grad_fn=<SelectBackward0>)\n",
      "you can see me for the queen of westeros ? you need to do it , i have to make him \n",
      " i will give them to the queen of a siege of a great warrior ? \n",
      " you have no need\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "saved_model= RNNModule(n_vocab, seq_size,\n",
    "                embedding_size, hidden_dim)\n",
    "saved_model.load_state_dict(torch.load('./models/model-1000.pth'))\n",
    "saved_model.eval()\n",
    "initial_words = [\"you\"]\n",
    "predict(device, saved_model, initial_words, n_vocab,\n",
    "        vocab_to_int, int_to_vocab, top_k=3, num_of_words=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What do you expect? They're savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I've never seen wildlings do a thing like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23906</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>Episode 6</td>\n",
       "      <td>The Iron Throne</td>\n",
       "      <td>brienne</td>\n",
       "      <td>I think we can all agree that ships take prece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23907</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>Episode 6</td>\n",
       "      <td>The Iron Throne</td>\n",
       "      <td>bronn</td>\n",
       "      <td>I think that's a very presumptuous statement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23908</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>Episode 6</td>\n",
       "      <td>The Iron Throne</td>\n",
       "      <td>tyrion lannister</td>\n",
       "      <td>I once brought a jackass and a honeycomb into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23909</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>Episode 6</td>\n",
       "      <td>The Iron Throne</td>\n",
       "      <td>man</td>\n",
       "      <td>The Queen in the North!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23910</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>Episode 6</td>\n",
       "      <td>The Iron Throne</td>\n",
       "      <td>all</td>\n",
       "      <td>The Queen in the North! The Queen in the North...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23911 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Release Date    Season    Episode     Episode Title              Name  \\\n",
       "0       2011-04-17  Season 1  Episode 1  Winter is Coming      waymar royce   \n",
       "1       2011-04-17  Season 1  Episode 1  Winter is Coming              will   \n",
       "2       2011-04-17  Season 1  Episode 1  Winter is Coming      waymar royce   \n",
       "3       2011-04-17  Season 1  Episode 1  Winter is Coming              will   \n",
       "4       2011-04-17  Season 1  Episode 1  Winter is Coming             gared   \n",
       "...            ...       ...        ...               ...               ...   \n",
       "23906   2019-05-19  Season 8  Episode 6   The Iron Throne           brienne   \n",
       "23907   2019-05-19  Season 8  Episode 6   The Iron Throne             bronn   \n",
       "23908   2019-05-19  Season 8  Episode 6   The Iron Throne  tyrion lannister   \n",
       "23909   2019-05-19  Season 8  Episode 6   The Iron Throne               man   \n",
       "23910   2019-05-19  Season 8  Episode 6   The Iron Throne               all   \n",
       "\n",
       "                                                Sentence  \n",
       "0      What do you expect? They're savages. One lot s...  \n",
       "1      I've never seen wildlings do a thing like this...  \n",
       "2                                 How close did you get?  \n",
       "3                                Close as any man would.  \n",
       "4                       We should head back to the wall.  \n",
       "...                                                  ...  \n",
       "23906  I think we can all agree that ships take prece...  \n",
       "23907      I think that's a very presumptuous statement.  \n",
       "23908  I once brought a jackass and a honeycomb into ...  \n",
       "23909                            The Queen in the North!  \n",
       "23910  The Queen in the North! The Queen in the North...  \n",
       "\n",
       "[23911 rows x 6 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('RNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8991468b00ae33e4a6326d948699fe66979b0646ad74599f69e9465fef39806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
